{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2578,
     "status": "ok",
     "timestamp": 1722585876712,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "jApAH2b8f-22",
    "outputId": "f9757b95-eaae-4a19-f868-ffdb9e063902"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1722585876713,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "FCFn8WusgAFf",
    "outputId": "08dfc1f4-571f-450c-ec1b-06c1818585d6"
   },
   "outputs": [],
   "source": [
    "# # navigate to root directory of current file in order to access other files relatively\n",
    "# %cd /content/drive/MyDrive/Colab\\ Notebooks/thesis-writing-1/eda-signal-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2292,
     "status": "ok",
     "timestamp": 1722585879002,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "dFCuHMTkgAfo",
    "outputId": "c2e5905a-9ab6-4570-e9c4-e747ebc5d5c5"
   },
   "outputs": [],
   "source": [
    "# !pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9188,
     "status": "ok",
     "timestamp": 1722585888188,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "xamxPIA0fRdO"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import requests\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# import and load model architectures as well as decoder\n",
    "from models.cueva import LSTM_FE\n",
    "from models.llanes_jurado import LSTM_CNN\n",
    "from utilities.preprocessors import correct_signals\n",
    "from utilities.loaders import load_meta_data, concur_load_data, charge_raw_data, _combine_data\n",
    "\n",
    "from utilities.visualizers import (\n",
    "    view_time_frame,\n",
    "    view_wavelet_coeffs,\n",
    "    analyze,\n",
    "    data_split_metric_values,\n",
    "    view_value_frequency,\n",
    "    multi_class_heatmap,\n",
    "    view_metric_values,\n",
    "    view_classified_labels,\n",
    "    view_label_freq,\n",
    "    disp_cat_feat,\n",
    "    plot_all_features,\n",
    "    describe_col,\n",
    "    ModelResults,\n",
    "    view_all_splits_results)\n",
    "\n",
    "from utilities.feature_extractors import (\n",
    "    concur_extract_features_from_all,\n",
    "    extract_features,\n",
    "    extract_features_hybrid,\n",
    "    extract_features_per_hour)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCKSmUssfRdP"
   },
   "source": [
    "# Downloading dataset\n",
    "\n",
    "If your project requires downloading a larger file, then you may run into issues using the steps above when you try to load the entire file into memory. To overcome those issues, you can download large files in a streaming fashion to avoid reading the content of large responses all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1722585888748,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "389MyfLAfRdQ"
   },
   "outputs": [],
   "source": [
    "# download_dataset(\"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/w8fxrg4pv5-2.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbnMS7eLfRdR"
   },
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1722585889293,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "b-4_e0rLfRdR"
   },
   "outputs": [],
   "source": [
    "# # Extract data from zip file\n",
    "# with zipfile.ZipFile('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)/EDABE dataset.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1722585889293,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "Msj09rqJfRdR"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_df_128hz = pd.read_csv('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)/Train/ahixac_expert1.csv', sep=';')\n",
    "# ahixac_eda_df_128hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1722585889293,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "ecqS1lB9fRdR"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_df_128hz.columns = ['time', 'raw_signal', 'clean_signal', 'label', 'auto_signal', 'pred_art', 'post_proc_pred_art']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585889293,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "aFfZfFzffRdR"
   },
   "outputs": [],
   "source": [
    "# start_time = ahixac_eda_df_128hz.iloc[0]['time']\n",
    "# start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585889293,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "DPcY3XWyfRdR"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_df_128hz.set_index(pd.date_range(start=start_time, periods=ahixac_eda_df_128hz.shape[0], freq=get_time_frequency(128)), inplace=True)\n",
    "# ahixac_eda_df_128hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykUcKH-ofRdR"
   },
   "source": [
    "# Downsampling 128hz signals to 16hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1722585889799,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "l8p74qMmfRdS"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_df_16hz = interpolate_signals(ahixac_eda_df_128hz, sample_rate=128, start_time=start_time, target_hz=16)\n",
    "# ahixac_eda_df_16hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWWCwhXpfRdS"
   },
   "source": [
    "# Low-pass filtering raw 128hz and 16hz signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1722585889800,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "UzAs854nfRdS"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_df_128hz['filtered_signal'] = butter_lowpass_filter(ahixac_eda_df_128hz['raw_signal'], cutoff=1.0, samp_freq=128, order=6)\n",
    "# ahixac_eda_df_16hz['filtered_signal'] = butter_lowpass_filter(ahixac_eda_df_16hz['raw_signal'], cutoff=1.0, samp_freq=16, order=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585889800,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "SNLV-xTEfRdS"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_df_128hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585889800,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "2CAzLL-bfRdS"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_df_128hz.iloc[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585889800,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "SrxzGu8GfRdS"
   },
   "outputs": [],
   "source": [
    "# timestamp_list = ahixac_eda_df_128hz.index.tolist()[::64]\n",
    "# timestamp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585889800,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "r39xXLS4fRdS"
   },
   "outputs": [],
   "source": [
    "# timestamp_list[-1].timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1722585890321,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "nUjj_wE1fRdT"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_df_16hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585890321,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "cJfEwX11fRdT"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_df_16hz[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585890321,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "1N5r_p5efRdT"
   },
   "outputs": [],
   "source": [
    "# view_time_frame(ahixac_eda_df_128hz, samp_freq=128, cols_to_use=['raw_signal', 'filtered_signal'], img_title='subject ahixac 128hz time frame')\n",
    "# view_time_frame(ahixac_eda_df_16hz, samp_freq=16, cols_to_use=['raw_signal', 'filtered_signal'], img_title='subject ahixac 16hz time frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnWYYF7bfRdU"
   },
   "source": [
    "# Iterate through signals per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585890321,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "8QXvgi4cfRdU"
   },
   "outputs": [],
   "source": [
    "# data_128hz = extract_features_per_hour(ahixac_eda_df_128hz, hertz=128, window_size=0.5, verbose=True)\n",
    "# data_128hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585890321,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "qMr5jjnUfRdU"
   },
   "outputs": [],
   "source": [
    "# data_16hz = extract_features_per_hour(ahixac_eda_df_16hz, hertz=16, window_size=0.5, verbose=True)\n",
    "# data_16hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cos7BKWafRdU"
   },
   "source": [
    "#### if we had a 128hz dataset with derived timestamps that increase every 0.5s such as this [0.0, 0.5, 1.0, 1.5, ..., 6506.0] then our segments would be:\n",
    "```\n",
    "[0.0, 0.5)\n",
    "[0.5, 1.0)\n",
    "[1.0, 1.5)\n",
    "...\n",
    "[6504.5, 6506.0)\n",
    "```\n",
    "\n",
    "#### 832830 / 64 is 13012.96875 or when \"`math.ceil()`ed\" is 13013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1722585890321,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "w5ZX204mfRdU"
   },
   "outputs": [],
   "source": [
    "# math.ceil(13012.96875), math.floor(13012.96875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1722585890706,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "P_9EsxbsfRdU"
   },
   "outputs": [],
   "source": [
    "# for feature_segments, labels in data_128hz:\n",
    "#     print(labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxefRwVRfRdU"
   },
   "source": [
    "#### here in the first hour of our data the number of artifacts out of all 7200 0.5s segments is 716 or roughly 9.9% of our data, and the number of non-artifacts out of all 7200 0.5s segments is 6484 or roughly 90% of our data\n",
    "\n",
    "#### For the second hour of our data the number of artifacts out of all 5813 0.5s segments is 208 or roughly 3.58% of our data, and the number of non-artifacts out of all 5813 0.5s segments is 5605 or roughly 96.42% of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1722585890706,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "Zy6i8JcefRdU"
   },
   "outputs": [],
   "source": [
    "# for feature_segments, labels in data_16hz:\n",
    "#     print(labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8J7B63RfRdU"
   },
   "source": [
    "#### Here the reason why we have almost the same number of artifact and non-artifact labels to the 128hz data is because we interpolated our 128hz data to 16hz thus losing some of our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1722585890706,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "2RJw6y8YfRdU"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_data = rejoin_data(data_128hz, data_16hz)\n",
    "# ahixac_eda_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2N9tOSK5fRdU"
   },
   "source": [
    "#### concatenating calculated features from 128hz and 16hz data of the first hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1722585890706,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "eUFLErSjfRdU"
   },
   "outputs": [],
   "source": [
    "# ahixac_eda_data[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUN8bzjHfRdV"
   },
   "source": [
    "# Now we ought to do these for all subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpMSz00qfRdV"
   },
   "source": [
    "# scanning train folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14836,
     "status": "ok",
     "timestamp": 1722585905541,
     "user": {
      "displayName": "Mikhail Cueva",
      "userId": "11170871238940341024"
     },
     "user_tz": -480
    },
    "id": "qcOwqv3ZfRdV",
    "outputId": "f2d7d269-a1c2-433e-a03d-7eff546796e5"
   },
   "outputs": [],
   "source": [
    "train_files = os.listdir('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)/Train/')\n",
    "train_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFuJL1d2fRdW"
   },
   "source": [
    "# Concurrently read each .csv file and use functions that will spit out the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "me9jt0sifRdW",
    "outputId": "4b25f068-5881-4856-d136-6effc81304ba"
   },
   "outputs": [],
   "source": [
    "# train_eda_data = concur_extract_features_from_all('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)/Train/', train_files, arch=\"ml\")\n",
    "# train_eda_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1i2UojpfRdW"
   },
   "source": [
    "#### Above code takes about 204 minutes or 3 hrs and 20 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbbxqWO9fRdW"
   },
   "outputs": [],
   "source": [
    "# # save each feature dataframe as a .csv file in the folder created earlier with the same names\n",
    "# for subject_name, (feature_segments, labels) in train_eda_data:\n",
    "#     feature_segments.to_csv(f'./data/Artifact Detection Data/train/{subject_name}_features.csv')\n",
    "#     labels.to_csv(f'./data/Artifact Detection Data/train/{subject_name}_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szb1u3CEfRdW"
   },
   "outputs": [],
   "source": [
    "test_files = os.listdir('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)/Test/')\n",
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHAFDfcefRdX"
   },
   "outputs": [],
   "source": [
    "# test_eda_data = concur_extract_features_from_all('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)/Test/', test_files, arch=\"ml\")\n",
    "# test_eda_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PakxYCGfRdX"
   },
   "outputs": [],
   "source": [
    "# # save each feature dataframe as a .csv file in the folder created earlier with the same names\n",
    "# for subject_name, (feature_segments, labels)  in test_eda_data:\n",
    "#     feature_segments.to_csv(f'./data/Artifact Detection Data/test/{subject_name}_features.csv')\n",
    "#     labels.to_csv(f'./data/Artifact Detection Data/test/{subject_name}_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section attempts outlier datapoint removal i.e. rows with purely zeros from newly generated features resulting from above lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahixac_features = pd.read_csv(f'./data/Artifact Detection Data/train/ahixac_expert1_features.csv', index_col=0)\n",
    "# ahixac_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recall axis 1 is the x axis and axis 0 is the y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_zero_rows = (ahixac_features != 0).any(axis=1)\n",
    "# non_zero_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahixac_features.index[~non_zero_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahixac_features[non_zero_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_zero_rows_alt = ~(ahixac_features == 0).all(axis=1)\n",
    "# non_zero_rows_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# # what I want is to individually open all the feature segment files as well as their corresponding label files\n",
    "# for train_subject_name in train_files:\n",
    "#     train_subject_name = re.sub(r\".csv\", \"\", train_subject_name)\n",
    "#     subject_features = pd.read_csv(f'./data/Artifact Detection Data/train/{train_subject_name}_features.csv', index_col=0)\n",
    "#     subject_labels = pd.read_csv(f'./data/Artifact Detection Data/train/{train_subject_name}_labels.csv', index_col=0)\n",
    "\n",
    "#     # allow modifications to the dataframe here i.e.\n",
    "#     # removing rows with purely 0.0 values for every feature/column\n",
    "#     # as these outliers can negatively impact the training of the \n",
    "#     # ml model\n",
    "#     non_zero_rows = (subject_features != 0).any(axis=1)\n",
    "\n",
    "#     # keep only the rows that are non zero rows\n",
    "#     # this goes also for rows in the subjects labels\n",
    "#     subject_features[non_zero_rows].to_csv(f'./data/Artifact Detection Data/train/{train_subject_name}_features.csv')\n",
    "#     subject_labels[non_zero_rows].to_csv(f'./data/Artifact Detection Data/train/{train_subject_name}_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section attempts to use lstm feature extractor model to convert eda signals to lstm features that a scikit learn svm can use as input. This will implement high level feature engineering for the hybrid lstm-svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects_signals, train_subjects_labels, train_subjects_names, train_subject_to_id = concur_load_data(feat_config=\"cueva\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_subjects_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subjects_signals, test_subjects_labels, test_subjects_names, test_subject_to_id = concur_load_data(feat_config=\"cueva\", data_split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_subjects_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from models.cueva import LSTM_FE \n",
    "\n",
    "# using tensorflow load weights of LSTM model\n",
    "# load train and cross signals of model\n",
    "lstm_fe_hp = load_meta_data('./saved/misc/cueva_lstm-fe_meta_data.json')\n",
    "lstm_fe = LSTM_FE(**lstm_fe_hp)\n",
    "lstm_fe.load_weights('./saved/weights/cueva_lstm-fe_21_0.7489.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_fe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer_2 = lstm_fe.get_layer('lstm-layer-2')\n",
    "lstm_layer_2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_fe.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_fe_main = tf.keras.Model(inputs=lstm_fe.inputs, outputs=lstm_layer_2.output)\n",
    "lstm_fe_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_fe_main.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subjects_signals[0] for instance previously had a shape (10701, 640, 1) and after feature extraction its shape  will now be (10701, 32) since the number of output units of the LSTM set was 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, train_subject_name in enumerate(train_subjects_names):\n",
    "    # use last lstm layer of trained side task model to predict\n",
    "    # output that will be used as features given the original signals \n",
    "    print(f'subject: {train_subject_name}')\n",
    "    print(f'initial shape: {train_subjects_signals[index].shape}')\n",
    "    train_subject_hof = lstm_fe_main.predict(train_subjects_signals[index])\n",
    "    print(f'output shape: {train_subject_hof.shape}')\n",
    "\n",
    "    # create columns with its length the same as the number of columns\n",
    "    # of the higher order features matrix \n",
    "    columns = [f'HOF_{i}' for i in range(1, train_subject_hof.shape[1] + 1)]\n",
    "    train_subject_hof_df = pd.DataFrame(train_subject_hof, columns=columns)\n",
    "\n",
    "    # save both lstm features and lstm labels\n",
    "    train_subject_hof_df.to_csv(f'./data/Hybrid Artifact Detection Data/train/{train_subject_name}_hof.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, test_subject_name in enumerate(test_subjects_names):\n",
    "    # use last lstm layer of tested side task model to predict\n",
    "    # output that will be used as features given the original signals \n",
    "    print(f'subject: {test_subject_name}')\n",
    "    print(f'initial shape: {test_subjects_signals[index].shape}')\n",
    "    test_subject_hof = lstm_fe_main.predict(test_subjects_signals[index])\n",
    "    print(f'output shape: {test_subject_hof.shape}')\n",
    "\n",
    "    # create columns with its length the same as the number of columns\n",
    "    # of the higher order features matrix \n",
    "    columns = [f'HOF_{i}' for i in range(1, test_subject_hof.shape[1] + 1)]\n",
    "    test_subject_hof_df = pd.DataFrame(test_subject_hof, columns=columns)\n",
    "\n",
    "    # save both lstm features and lstm labels\n",
    "    test_subject_hof_df.to_csv(f'./data/Hybrid Artifact Detection Data/test/{test_subject_name}_hof.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this next section will implement low level feature engineering for hybrid lstm-svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_hybrid_eda_data = concur_extract_features_from_all('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)/Train/', train_files, arch=\"hybrid\")\n",
    "# train_hybrid_eda_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save each feature dataframe as a .csv file in the folder created earlier with the same names\n",
    "# for subject_name, (feature_segments, labels) in train_hybrid_eda_data:\n",
    "#     feature_segments.to_csv(f'./data/Hybrid Artifact Detection Data/train/{subject_name}_lof.csv')\n",
    "#     labels.to_csv(f'./data/Hybrid Artifact Detection Data/train/{subject_name}_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_hybrid_eda_data = concur_extract_features_from_all('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)/Test/', test_files, arch=\"hybrid\")\n",
    "# test_hybrid_eda_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save each feature dataframe as a .csv file in the folder created earlier with the same names\n",
    "# for subject_name, (feature_segments, labels) in test_hybrid_eda_data:\n",
    "#     feature_segments.to_csv(f'./data/Hybrid Artifact Detection Data/test/{subject_name}_lof.csv')\n",
    "#     labels.to_csv(f'./data/Hybrid Artifact Detection Data/test/{subject_name}_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8V62G-rmfRdX"
   },
   "outputs": [],
   "source": [
    "# # once notebook reaches end remove data to clear space\n",
    "# os.remove('./data/EDABE dataset.zip')\n",
    "# os.remove('./data/Electrodermal Activity artifact correction BEnchmark (EDABE)')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "thesis-writing-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
